{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"i1\"> Data 512 - A4 : Predicting Earthquakes : Final Project Plan </h1>\n",
    "\n",
    "Gautam Moogimane <br>\n",
    "University of Washington - Fall 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"i1\">I. Introduction </h2>     \n",
    "  \n",
    "Having stayed in Japan for a long time, I've been accustomed to getting up at odd hours, with everything shaking around me. Tremors and earthquakes are so common, its rare for a week to go by without one. Considering the amount of damage these natural disasters are capable of, the fact that we are no closer to predicting them than we were a 100 years ago, is slightly surprising to say the least. With this analysis, I aim to use machine learning to analyze historic earthquake data from around the world, and use to it to hopefully come up with some observations about earthquakes in the future.\n",
    "\n",
    "As per the statistics, there are hundreds of earthquakes that happen every day around the globe, with magnitudes ranging from 2-4 on the richter scale. The larger ones, between 5-7 on the scale occur every week or so, while the biggest at 7.5 and above are seen once a year. The 20ll Japan earthquake with its epicenter in Fukushima only had a magnitude of about 6.6, but was strong enough to cause buildings in Tokyo, which is a 100 miles away from Fukushima, to sway for around 30 seconds. Electricty went down, trains were stalled on the tracks, traffic came to a standstill, and thousands of people took to the streets, walking many miles to get back home. \n",
    "\n",
    "The aim of this study is not to break some new ground as far as predicting earthquakes go, but a way to see how appropriate or accurate machine learning can be in this situation. Statistics deals with probabilites, and machine learning, which applies these concepts on a computer, can only predict with a certain amount of accuracy, based on the data that it is trained on. To accurately predict earthquakes, one needs to be able to say with a degree of certainty, what the exact location, time of occurance and the magnitude will be. Considering the data we have, and how spread out the locations are, it would be an unrealistic goal trying to achieve this using machine learning at this point in time. Instead, with this analysis, given a certain location( like country, rather than latitudes and longitudes), and time( year, instead of down to the exact second), if we can come up with information about the magnitude of the next earthquake/earthquakes, based on what happened in the past, that would be a good start. \n",
    "\n",
    "From a human centered ethics perspective, the good part is that the data is devoid of any human bias in it, and hopefully does not contain any input errors either. From a personal standpoint, I would need to ensure my experience in Japan, does not make me expect or not expect certain results from the model, thereby skewing the predictions in a particular direction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"i2\">II. Data</h2> \n",
    "\n",
    "The data is from the significant earthquake database, and contains historic data from 2150 BC to the present day, of earthquakes from all over the world. The data is constantly updated to reflect the latest events.\n",
    "\n",
    "\n",
    "As per the description from the 'data.nodc.noaa.gov' site where the data is hosted:\n",
    " > The Significant Earthquake Database is a global listing of over 5,700 earthquakes from 2150 BC to the present. A significant earthquake is classified as one that meets at least one of the following criteria:\n",
    " \n",
    " > caused deaths, caused moderate damage (approximately 1 million dollars or more), magnitude 7.5 or greater, Modified Mercalli Intensity (MMI) X or greater, or the earthquake generated a tsunami. \n",
    " \n",
    " > The database provides information on the date and time of occurrence, latitude and longitude, focal depth, magnitude, maximum MMI intensity, and socio-economic data such as the total number of casualties, injuries, houses destroyed, and houses damaged, and dollar damage estimates. \n",
    "References, political geography, and additional comments are also provided for each earthquake. If the earthquake was associated with a tsunami or volcanic eruption, it is flagged and linked to the related tsunami event or significant volcanic eruption.\n",
    " \n",
    "\n",
    "The fields that are key from the perspective of our analysis are detailed in the table below <br>\n",
    "\n",
    "| Field Name    | Datatype      | Description |\n",
    "| :-------------: | :-------------: | :-------------: |\n",
    "|  Year | Integer | The year of occurence  |\n",
    "| Focal Depth  | Integer  | Depth of the epicenter |\n",
    "| Eq_Primary | Float | Magnitude of the earthquake |\n",
    "| Country | String | Name of the country |\n",
    "| Location_Name | String | Specific location in the country | \n",
    "| Latitude | Float | Coordinates of the exact location |\n",
    "| Longitude | Float | Coordinates of the exact location |\n",
    "\n",
    "\n",
    "\n",
    "The data can be downloaded in a tab separated file, and can be imported into excel or python for analysis.\n",
    "For more information about the data and downloading it, please access the link below <br>\n",
    "[National Geophysical Data Center / World Data Service (NGDC/WDS): Significant Earthquake Database. National Geophysical Data Center, NOAA](http://dx.doi.org/10.7289/V5TD9V7K)\n",
    "\n",
    "\n",
    "__Concerns__\n",
    "\n",
    "The data needs to be cleaned before it can be used for analysis. Many of the fields have data missing, especially from the earlier years, and hence makes no sense to include. Initial number of data points are around 6000, and if we lose too much data after cleaning, it would be hard to develop an accurate model.\n",
    "\n",
    "__License__\n",
    "\n",
    "The data is hosted on a public information website, and can be freely distributed and copied, with the appropriate credits.\n",
    "\n",
    "A copy of the text from the webiste is quoted below for reference:\n",
    "\n",
    "> The National Centers for Environmental Information (formerly the National Geophysical Data Center) website is provided as a public service by the U.S. Department of Commerce, National Oceanic and Atmospheric Administration (NOAA), National Environmental Satellite, Data and Information Service (NESDIS). Information presented on these web pages is considered public information and may be distributed or copied. \n",
    "\n",
    "More details about their privacy policy can be found at the link below <br>\n",
    "[NOAA privacy](https://www.ngdc.noaa.gov/ngdcinfo/privacy.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"i3\">III. Research Questions </h2>\n",
    "\n",
    "Some of the questions I hope to answer are:\n",
    "\n",
    "1. What is the likelihood of an earthquake occuring in the US in 2019? What would its approximate magnitude be?\n",
    "2. When is the next major(+7 magnitude) earthquake going to occur? And in which country?\n",
    "3. How many damaging earthquakes can we expect around the world in the next year?\n",
    "4. What are the top 5 countries as far as frequency and magnitude of earthquakes are concerned?\n",
    "5. Which fault line is the most active, and likely to shift in the near future?\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "1. Major earthquake, probably less than 20%. Minor earthquakes happen all the time.\n",
    "2. To be predicted by the model.\n",
    "3. Atleast one, if not more\n",
    "4. This can probably be answered by Google, but would be interesting to predict.\n",
    "5. Most active one can be found on google, although predicting when is tricky.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"i4\">IV. Software tools and Analysis </h2>\n",
    "\n",
    "Most of the analysis will be performed using Python and its libraries like Pandas and Numpy with matplotlib aiding in any visualizations I might come up with. The data size is not too big, which means I should be able to train and test my models locally, without needing support from cloud computing resources (Amazon EC2). <br>\n",
    "The idea is to clean the data and delete the rows where data is missing, filter out columns that will be used as features and labels, split the data into an appropriate training, test and validation set and use Scikit-learn machine learning library to test different models. <br>\n",
    "Support vector machines, random forests and even recurrent neural networks via Tensorflow, are some of the algorithms I intend to test the data on, finally deciding on one based on how it performs with the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"i5\">V. Resources </h2> \n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6033417/ \n",
    "\n",
    "https://earthquake.usgs.gov/data/data.php#eq\n",
    "\n",
    "https://www.cam.ac.uk/research/news/machine-learning-used-to-predict-earthquakes-in-a-lab-setting\n",
    "\n",
    "https://arxiv.org/pdf/1702.05774.pdf\n",
    "\n",
    "https://www.scientificamerican.com/article/can-artificial-intelligence-predict-earthquakes/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
